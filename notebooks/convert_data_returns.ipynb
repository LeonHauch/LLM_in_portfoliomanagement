{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_parquet(\"../data/preprocessed/prices.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([('Adj Close', 'BNP.PA'),\n",
      "            (    'Close', 'BNP.PA'),\n",
      "            (     'High', 'BNP.PA'),\n",
      "            (      'Low', 'BNP.PA'),\n",
      "            (     'Open', 'BNP.PA'),\n",
      "            (   'Volume', 'BNP.PA'),\n",
      "            ('Adj Close',  'ML.PA'),\n",
      "            (    'Close',  'ML.PA'),\n",
      "            (     'High',  'ML.PA'),\n",
      "            (      'Low',  'ML.PA'),\n",
      "            ...\n",
      "            (     'High',  'SU.PA'),\n",
      "            (      'Low',  'SU.PA'),\n",
      "            (     'Open',  'SU.PA'),\n",
      "            (   'Volume',  'SU.PA'),\n",
      "            ('Adj Close', 'VIV.PA'),\n",
      "            (    'Close', 'VIV.PA'),\n",
      "            (     'High', 'VIV.PA'),\n",
      "            (      'Low', 'VIV.PA'),\n",
      "            (     'Open', 'VIV.PA'),\n",
      "            (   'Volume', 'VIV.PA')],\n",
      "           names=['Price', 'Ticker'], length=162)\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_close = df.xs('Adj Close', axis=1, level='Price')\n",
    "\n",
    "# Compute log returns\n",
    "log_returns = np.log(adj_close / adj_close.shift(1))\n",
    "\n",
    "# Create MultiIndex for log returns\n",
    "log_returns.columns = pd.MultiIndex.from_product(\n",
    "    [['LogReturn'], log_returns.columns],\n",
    "    names=['Price', 'Ticker']\n",
    ")\n",
    "\n",
    "# Concatenate and sort\n",
    "df_combined = pd.concat([df, log_returns], axis=1).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([('Adj Close', 'ACA.PA'),\n",
      "            ('Adj Close',  'AI.PA'),\n",
      "            ('Adj Close', 'AIR.PA'),\n",
      "            ('Adj Close', 'ATO.PA'),\n",
      "            ('Adj Close', 'BNP.PA'),\n",
      "            ('Adj Close',  'CA.PA'),\n",
      "            ('Adj Close', 'CAP.PA'),\n",
      "            ('Adj Close',  'DG.PA'),\n",
      "            ('Adj Close', 'DSY.PA'),\n",
      "            ('Adj Close',  'EL.PA'),\n",
      "            ...\n",
      "            (   'Volume',  'ML.PA'),\n",
      "            (   'Volume',  'OR.PA'),\n",
      "            (   'Volume',  'RI.PA'),\n",
      "            (   'Volume', 'RNO.PA'),\n",
      "            (   'Volume', 'SAN.PA'),\n",
      "            (   'Volume',  'SU.PA'),\n",
      "            (   'Volume',  'SW.PA'),\n",
      "            (   'Volume', 'VIE.PA'),\n",
      "            (   'Volume', 'VIV.PA'),\n",
      "            (   'Volume', 'WLN.PA')],\n",
      "           names=['Price', 'Ticker'], length=189)\n"
     ]
    }
   ],
   "source": [
    "print(df_combined.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_combined.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_summary = df_combined.isnull().sum()\n",
    "nan_summary = nan_summary[nan_summary > 0] \n",
    "print(nan_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = df_combined.columns.get_level_values(\"Ticker\").unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = [\"Adj Close\", \"Volume\", \"LogReturn\"]\n",
    "cols_to_keep = [col for col in df_combined.columns if col[0] in features_to_keep]\n",
    "df_filtered = df_combined[cols_to_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_dfs = []\n",
    "for feature in [\"Adj Close\", \"Volume\"]:\n",
    "    feature_data = df_filtered.xs(feature, axis=1, level='Price')\n",
    "    normalized_cols = []\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        series = feature_data[ticker].copy()\n",
    "        scaler = StandardScaler()\n",
    "        normalized_values = scaler.fit_transform(series.values.reshape(-1, 1)).flatten()\n",
    "        normalized_cols.append(pd.Series(normalized_values, index=series.index, name=ticker))\n",
    "    \n",
    "    normalized_df = pd.concat(normalized_cols, axis=1)\n",
    "    normalized_df.columns = pd.MultiIndex.from_product([[feature], normalized_df.columns], names=['Price', 'Ticker'])\n",
    "    normalized_dfs.append(normalized_df)\n",
    "\n",
    "# Keep LogReturn as-is\n",
    "logreturns = df_filtered.xs('LogReturn', axis=1, level='Price')\n",
    "logreturns.columns = pd.MultiIndex.from_product([['LogReturn'], logreturns.columns], names=['Price', 'Ticker'])\n",
    "normalized_dfs.append(logreturns)\n",
    "\n",
    "# Combine all features\n",
    "data_ppo = pd.concat(normalized_dfs, axis=1).sort_index(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing NaN: (1792, 81)\n"
     ]
    }
   ],
   "source": [
    "data_ppo = data_ppo.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating technical indicators...\n"
     ]
    }
   ],
   "source": [
    "def calculate_rsi(prices, window=14):\n",
    "    \"\"\"Calculate RSI indicator\"\"\"\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def calculate_macd(prices, fast=12, slow=26, signal=9):\n",
    "    \"\"\"Calculate MACD indicator\"\"\"\n",
    "    ema_fast = prices.ewm(span=fast).mean()\n",
    "    ema_slow = prices.ewm(span=slow).mean()\n",
    "    macd_line = ema_fast - ema_slow\n",
    "    signal_line = macd_line.ewm(span=signal).mean()\n",
    "    macd_histogram = macd_line - signal_line\n",
    "    return macd_line, signal_line, macd_histogram\n",
    "\n",
    "def calculate_bollinger_bands(prices, window=20, num_std=2):\n",
    "    \"\"\"Calculate Bollinger Bands\"\"\"\n",
    "    rolling_mean = prices.rolling(window=window).mean()\n",
    "    rolling_std = prices.rolling(window=window).std()\n",
    "    upper_band = rolling_mean + (rolling_std * num_std)\n",
    "    lower_band = rolling_mean - (rolling_std * num_std)\n",
    "    bb_position = (prices - lower_band) / (upper_band - lower_band)  # 0-1 normalized position\n",
    "    return bb_position\n",
    "\n",
    "def calculate_rolling_volatility(returns, window=20):\n",
    "    \"\"\"Calculate rolling volatility from returns\"\"\"\n",
    "    return returns.rolling(window=window).std() * np.sqrt(252)  # Annualized\n",
    "\n",
    "def calculate_volume_sma_ratio(volume, window=20):\n",
    "    \"\"\"Volume relative to its moving average\"\"\"\n",
    "    volume_sma = volume.rolling(window=window).mean()\n",
    "    return volume / volume_sma\n",
    "\n",
    "# Extract price and volume data for indicator calculation\n",
    "adj_close = data_ppo.xs('Adj Close', axis=1, level='Price')  # This is already normalized\n",
    "volume = data_ppo.xs('Volume', axis=1, level='Price')      # This is already normalized\n",
    "logreturns = data_ppo.xs('LogReturn', axis=1, level='Price')\n",
    "\n",
    "print(\"Calculating technical indicators...\")\n",
    "\n",
    "# We need original prices for some indicators, so let's get them\n",
    "# Load original data for indicator calculation\n",
    "df_original = df_combined\n",
    "adj_close_orig = df_original.xs('Adj Close', axis=1, level='Price')\n",
    "volume_orig = df_original.xs('Volume', axis=1, level='Price')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating RSI...\n",
      "Calculating MACD...\n",
      "Calculating Bollinger Bands...\n",
      "Calculating Rolling Volatility...\n",
      "Calculating Volume Ratio...\n",
      "Combining all features...\n"
     ]
    }
   ],
   "source": [
    "indicator_dfs = []\n",
    "tickers = adj_close.columns\n",
    "\n",
    "# 1. RSI (momentum)\n",
    "print(\"Calculating RSI...\")\n",
    "rsi_data = []\n",
    "for ticker in tickers:\n",
    "    rsi = calculate_rsi(adj_close_orig[ticker])\n",
    "    # Normalize RSI to 0-1 range (RSI is naturally 0-100)\n",
    "    rsi_normalized = (rsi - 50) / 50  # Center around 0, range roughly -1 to 1\n",
    "    rsi_data.append(pd.Series(rsi_normalized, index=adj_close.index, name=ticker))\n",
    "\n",
    "rsi_df = pd.concat(rsi_data, axis=1)\n",
    "rsi_df.columns = pd.MultiIndex.from_product([['RSI'], rsi_df.columns], names=['Price', 'Ticker'])\n",
    "indicator_dfs.append(rsi_df)\n",
    "\n",
    "# 2. MACD (trend and momentum)\n",
    "print(\"Calculating MACD...\")\n",
    "macd_data = []\n",
    "for ticker in tickers:\n",
    "    macd_line, signal_line, macd_histogram = calculate_macd(adj_close_orig[ticker])\n",
    "    # Use MACD histogram (already oscillates around 0)\n",
    "    # Normalize by rolling standard deviation\n",
    "    macd_norm = macd_histogram / macd_histogram.rolling(window=50).std()\n",
    "    macd_data.append(pd.Series(macd_norm, index=adj_close.index, name=ticker))\n",
    "\n",
    "macd_df = pd.concat(macd_data, axis=1)\n",
    "macd_df.columns = pd.MultiIndex.from_product([['MACD'], macd_df.columns], names=['Price', 'Ticker'])\n",
    "indicator_dfs.append(macd_df)\n",
    "\n",
    "# 3. Bollinger Band Position (mean reversion)\n",
    "print(\"Calculating Bollinger Bands...\")\n",
    "bb_data = []\n",
    "for ticker in tickers:\n",
    "    bb_position = calculate_bollinger_bands(adj_close_orig[ticker])\n",
    "    # BB position is already 0-1, center it around 0\n",
    "    bb_centered = (bb_position - 0.5) * 2  # Now -1 to 1 range\n",
    "    bb_data.append(pd.Series(bb_centered, index=adj_close.index, name=ticker))\n",
    "\n",
    "bb_df = pd.concat(bb_data, axis=1)\n",
    "bb_df.columns = pd.MultiIndex.from_product([['BB_Position'], bb_df.columns], names=['Price', 'Ticker'])\n",
    "indicator_dfs.append(bb_df)\n",
    "\n",
    "# 4. Rolling Volatility (risk measure)\n",
    "print(\"Calculating Rolling Volatility...\")\n",
    "vol_data = []\n",
    "for ticker in tickers:\n",
    "    rolling_vol = calculate_rolling_volatility(logreturns[ticker])\n",
    "    # Normalize volatility using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    vol_norm = scaler.fit_transform(rolling_vol.dropna().values.reshape(-1, 1)).flatten()\n",
    "    vol_series = pd.Series(index=rolling_vol.index, dtype=float)\n",
    "    vol_series.loc[rolling_vol.dropna().index] = vol_norm\n",
    "    vol_data.append(pd.Series(vol_series, index=adj_close.index, name=ticker))\n",
    "\n",
    "vol_df = pd.concat(vol_data, axis=1)\n",
    "vol_df.columns = pd.MultiIndex.from_product([['Volatility'], vol_df.columns], names=['Price', 'Ticker'])\n",
    "indicator_dfs.append(vol_df)\n",
    "\n",
    "# 5. Volume Ratio (volume momentum)\n",
    "print(\"Calculating Volume Ratio...\")\n",
    "vol_ratio_data = []\n",
    "for ticker in tickers:\n",
    "    vol_ratio = calculate_volume_sma_ratio(volume_orig[ticker])\n",
    "    # Log transform and normalize\n",
    "    vol_ratio_log = np.log(vol_ratio.clip(lower=0.1))  # Avoid log(0)\n",
    "    scaler = StandardScaler()\n",
    "    vol_ratio_norm = scaler.fit_transform(vol_ratio_log.dropna().values.reshape(-1, 1)).flatten()\n",
    "    vol_ratio_series = pd.Series(index=vol_ratio_log.index, dtype=float)\n",
    "    vol_ratio_series.loc[vol_ratio_log.dropna().index] = vol_ratio_norm\n",
    "    vol_ratio_data.append(pd.Series(vol_ratio_series, index=adj_close.index, name=ticker))\n",
    "\n",
    "vol_ratio_df = pd.concat(vol_ratio_data, axis=1)\n",
    "vol_ratio_df.columns = pd.MultiIndex.from_product([['Volume_Ratio'], vol_ratio_df.columns], names=['Price', 'Ticker'])\n",
    "indicator_dfs.append(vol_ratio_df)\n",
    "\n",
    "# Combine original features with new indicators\n",
    "print(\"Combining all features...\")\n",
    "all_features = [data_ppo] + indicator_dfs\n",
    "data_ppo_enhanced = pd.concat(all_features, axis=1).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing NaN: (1744, 216)\n",
      "\n",
      "Feature summary:\n",
      "Features: ['Adj Close', 'BB_Position', 'LogReturn', 'MACD', 'RSI', 'Volatility', 'Volume', 'Volume_Ratio']\n",
      "Number of tickers: 27\n",
      "Total columns: 216\n",
      "\n",
      "Feature statistics (first 5 columns):\n",
      "Price     Adj Close                                                    \n",
      "Ticker       ACA.PA        AI.PA       AIR.PA       ATO.PA       BNP.PA\n",
      "count   1744.000000  1744.000000  1744.000000  1744.000000  1744.000000\n",
      "mean       0.000355     0.039857     0.026985    -0.044309     0.004629\n",
      "std        1.013749     0.985065     1.000512     0.977684     1.013735\n",
      "min       -2.115286    -1.552469    -2.519697    -1.399553    -2.078222\n",
      "25%       -0.639548    -0.773973    -0.600832    -1.060883    -0.850501\n",
      "50%       -0.218137    -0.069115     0.031741     0.073531    -0.095871\n",
      "75%        0.467950     0.857378     0.732689     0.834278     0.880171\n",
      "max        2.653312     2.064923     2.539568     3.021541     2.234117\n",
      "\n",
      "Data quality check:\n",
      "Any NaN values: 0\n",
      "Any infinite values: 0\n",
      "Date range: 2018-03-12 00:00:00 to 2024-12-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "data_ppo_enhanced = data_ppo_enhanced.dropna()\n",
    "print(f\"After removing NaN: {data_ppo_enhanced.shape}\")\n",
    "\n",
    "# Check the structure\n",
    "print(\"\\nFeature summary:\")\n",
    "feature_names = data_ppo_enhanced.columns.get_level_values('Price').unique()\n",
    "print(f\"Features: {list(feature_names)}\")\n",
    "print(f\"Number of tickers: {len(tickers)}\")\n",
    "print(f\"Total columns: {len(data_ppo_enhanced.columns)}\")\n",
    "\n",
    "# Verify all features are properly normalized (should be roughly mean=0, std=1)\n",
    "print(\"\\nFeature statistics (first 5 columns):\")\n",
    "print(data_ppo_enhanced.iloc[:, :5].describe())\n",
    "\n",
    "# Check for any remaining issues\n",
    "print(f\"\\nData quality check:\")\n",
    "print(f\"Any NaN values: {data_ppo_enhanced.isnull().sum().sum()}\")\n",
    "print(f\"Any infinite values: {np.isinf(data_ppo_enhanced.select_dtypes(include=[np.number])).sum().sum()}\")\n",
    "print(f\"Date range: {data_ppo_enhanced.index.min()} to {data_ppo_enhanced.index.max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PPO FORMAT CHECK ---\n",
      "Flattened format would have 216 features per timestep\n",
      "Example column names: ['Adj Close_ACA.PA', 'Adj Close_AI.PA', 'Adj Close_AIR.PA', 'Adj Close_ATO.PA', 'Adj Close_BNP.PA', 'Adj Close_CA.PA', 'Adj Close_CAP.PA', 'Adj Close_DG.PA', 'Adj Close_DSY.PA', 'Adj Close_EL.PA']...\n",
      "Ready for PPO: ✅\n",
      "\n",
      "Sample data (first 3 rows, first 10 columns):\n",
      "Price      Adj Close                                                    \\\n",
      "Ticker        ACA.PA     AI.PA    AIR.PA    ATO.PA    BNP.PA     CA.PA   \n",
      "Date                                                                     \n",
      "2018-03-12 -0.231699 -1.460016 -0.776506  1.400818 -0.280430 -0.146494   \n",
      "2018-03-13 -0.252785 -1.483130 -0.784590  1.346474 -0.295871 -0.249795   \n",
      "2018-03-14 -0.296365 -1.495737 -0.800373  1.372411 -0.344767 -0.373755   \n",
      "\n",
      "Price                                               \n",
      "Ticker        CAP.PA     DG.PA    DSY.PA     EL.PA  \n",
      "Date                                                \n",
      "2018-03-12 -1.104773 -1.251393 -1.488050 -1.131576  \n",
      "2018-03-13 -1.121182 -1.273384 -1.479519 -1.156931  \n",
      "2018-03-14 -1.112431 -1.257675 -1.477082 -1.148480  \n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- PPO FORMAT CHECK ---\")\n",
    "feature_order = ['Adj Close', 'BB_Position', 'LogReturn', 'MACD', 'RSI', 'Volatility', 'Volume', 'Volume_Ratio']\n",
    "ticker_order = sorted(tickers)\n",
    "\n",
    "# Show what the flattened column names would look like\n",
    "flat_columns = []\n",
    "for feature in feature_order:\n",
    "    for ticker in ticker_order:\n",
    "        flat_columns.append(f\"{feature}_{ticker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final PPO data shape: (1744, 216)\n",
      "Date range: 2018-03-12 00:00:00 to 2024-12-30 00:00:00\n",
      "\n",
      "Final quality check:\n",
      "Any NaN values: 0\n",
      "Any infinite values: 0\n",
      "\n",
      "Sample PPO data (first 3 rows, first 10 columns):\n",
      "            Adj Close_ACA.PA  Adj Close_AI.PA  Adj Close_AIR.PA  \\\n",
      "Date                                                              \n",
      "2018-03-12         -0.231699        -1.460016         -0.776506   \n",
      "2018-03-13         -0.252785        -1.483130         -0.784590   \n",
      "2018-03-14         -0.296365        -1.495737         -0.800373   \n",
      "\n",
      "            Adj Close_ATO.PA  Adj Close_BNP.PA  Adj Close_CA.PA  \\\n",
      "Date                                                              \n",
      "2018-03-12          1.400818         -0.280430        -0.146494   \n",
      "2018-03-13          1.346474         -0.295871        -0.249795   \n",
      "2018-03-14          1.372411         -0.344767        -0.373755   \n",
      "\n",
      "            Adj Close_CAP.PA  Adj Close_DG.PA  Adj Close_DSY.PA  \\\n",
      "Date                                                              \n",
      "2018-03-12         -1.104773        -1.251393         -1.488050   \n",
      "2018-03-13         -1.121182        -1.273384         -1.479519   \n",
      "2018-03-14         -1.112431        -1.257675         -1.477082   \n",
      "\n",
      "            Adj Close_EL.PA  \n",
      "Date                         \n",
      "2018-03-12        -1.131576  \n",
      "2018-03-13        -1.156931  \n",
      "2018-03-14        -1.148480  \n",
      "\n",
      "Column names: ['Adj Close_ACA.PA', 'Adj Close_AI.PA', 'Adj Close_AIR.PA', 'Adj Close_ATO.PA', 'Adj Close_BNP.PA', 'Adj Close_CA.PA', 'Adj Close_CAP.PA', 'Adj Close_DG.PA', 'Adj Close_DSY.PA', 'Adj Close_EL.PA']...\n"
     ]
    }
   ],
   "source": [
    "def flatten_multiindex_data(df, feature_order, ticker_order):\n",
    "    \"\"\"Efficiently flatten MultiIndex DataFrame for PPO\"\"\"\n",
    "    flattened_data = []\n",
    "    \n",
    "    for feature in feature_order:\n",
    "        try:\n",
    "            feature_data = df.xs(feature, axis=1, level='Price')\n",
    "            for ticker in ticker_order:\n",
    "                flattened_data.append(feature_data[ticker].values)\n",
    "        except KeyError:\n",
    "            print(f\"Warning: Feature {feature} not found\")\n",
    "            # Add zeros if feature missing\n",
    "            for ticker in ticker_order:\n",
    "                flattened_data.append(np.zeros(len(df)))\n",
    "    \n",
    "    return np.column_stack(flattened_data)\n",
    "\n",
    "# Create flattened array\n",
    "flattened_array = flatten_multiindex_data(data_ppo_enhanced, feature_order, ticker_order)\n",
    "\n",
    "# Create final PPO DataFrame\n",
    "data_ppo_flat = pd.DataFrame(\n",
    "    flattened_array, \n",
    "    index=data_ppo_enhanced.index, \n",
    "    columns=flat_columns\n",
    ")\n",
    "\n",
    "print(f\"Final PPO data shape: {data_ppo_flat.shape}\")\n",
    "print(f\"Date range: {data_ppo_flat.index.min()} to {data_ppo_flat.index.max()}\")\n",
    "\n",
    "# Quality check\n",
    "print(f\"\\nFinal quality check:\")\n",
    "print(f\"Any NaN values: {data_ppo_flat.isnull().sum().sum()}\")\n",
    "print(f\"Any infinite values: {np.isinf(data_ppo_flat).sum().sum()}\")\n",
    "\n",
    "# Show sample\n",
    "print(f\"\\nSample PPO data (first 3 rows, first 10 columns):\")\n",
    "print(data_ppo_flat.iloc[:3, :10])\n",
    "print(f\"\\nColumn names: {list(data_ppo_flat.columns[:10])}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved PPO-ready data to data_ppo.parquet\n"
     ]
    }
   ],
   "source": [
    "# Save the flattened PPO-ready data\n",
    "data_ppo_flat.to_parquet(\"../data/preprocessed/data_ppo.parquet\")\n",
    "print(\"✅ Saved PPO-ready data to data_ppo.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fr_sent_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
